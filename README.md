# unir-predictivo-andina-espana

Para visualizar el tablero con las predicciones y análisis descriptivo, ingrese al siguiente enlace: [Tablero Predicción y Análisis de la Demanda y Suministro de Productos entre la Comunidad Andina y España](https://lookerstudio.google.com/u/1/reporting/193798f9-5ef9-47f3-bcdc-574e3413392a/page/p_zewzg6d5nd)


Para visualizar resultados de perfilamiento o notebooks debe ingresar al siguiente link: https://danilo06.github.io/unir-predictivo-andina-espana/

## Descripción de Carpetas y Archivos

- **1 - Complementos Visualizacion HTML/**: Contiene archivos HTML generados para la visualización de datos.
  - `1 - Transient to Raw.html`: Visualización de datos en la fase de Transient a Raw.
  - `2 - Perfilado.html`: Informe de perfilado de datos.
  - `2 - Raw to Trusted.html`: Visualización de datos en la fase de Raw a Trusted.

- **2 - Comandos Bash/**: Scripts Bash para configurar el entorno local de Google Cloud Platform (GCP).
  - `Configurar GCP en local.bash`: Script para configurar GCP en el entorno local.

- **3 - Disponibilización en arquitectura cloud/**: Notebooks de Jupyter para la transformación de datos en la nube.
  - `1 - Transient to Raw.ipynb`: Notebook para mover datos de la zona Transient a la zona Raw.
  - `2 - Raw to Trusted.ipynb`: Notebook para mover datos de la zona Raw a la zona Trusted.

- **4 - Comprension de los datos/**: Contiene scripts SQL y archivos HTML para el análisis y perfilado de datos.
  - `1 - Delimitación del Conjunto de Datos.sql`: Script SQL para delimitar el conjunto de datos.
  - `perfilado_sweetviz/`: Informes de perfilado generados con Sweetviz.
  - `perfilado_ydata/`: Informes de perfilado generados con YData.

## Herramientas Utilizadas

- **Spark**: Utilizado para el procesamiento de grandes volúmenes de datos.
- **Google Cloud Platform (GCP)**: Plataforma utilizada para la infraestructura en la nube.
- **Cloud Storage de GCP**: Servicio de almacenamiento en la nube utilizado para guardar datos.
- **Dataproc de GCP**: Servicio de GCP utilizado para ejecutar trabajos de procesamiento de datos.
- **BigQuery de GCP**: Almacén de datos en la nube utilizado para análisis de grandes volúmenes de datos.
- **PySpark**: API de Python para trabajar con Apache Spark.
- **Python**: Lenguaje de programación utilizado para el desarrollo de scripts y notebooks.
- **SQL**: Lenguaje utilizado para consultas y manipulación de bases de datos.
- **Looker Studio**: Herramienta de visualización de datos utilizada para crear informes y dashboards.
- **YData**: Utilizado para generar informes de perfilado de datos.
- **Sweetviz**: Utilizado para generar visualizaciones y análisis detallados de los datos.

## Enlace al Sitio Web

Para visualizar el tablero con las predicciones y análisis descriptivo, ingrese al siguiente enlace: [Predicción y Análisis de la Demanda y Suministro de Productos entre la Comunidad Andina y España](https://lookerstudio.google.com/u/1/reporting/193798f9-5ef9-47f3-bcdc-574e3413392a/page/p_zewzg6d5nd)

Para visualizar los resultados de perfilamiento y notebooks en el sitio web, ingrese al siguiente enlace: [https://danilo06.github.io/unir-predictivo-andina-espana/](https://danilo06.github.io/unir-predictivo-andina-espana/)

## Contacto

Para cualquier consulta o colaboración, por favor contacte al mantenedores del proyecto.

